# llm-eval
General codes for evaluating LLMs with comprehensive benchmarks, including closed and open format. 
